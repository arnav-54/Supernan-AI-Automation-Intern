{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "introduction"
            },
            "source": [
                "# üöÄ Supernan AI Dubbing: Premium End-to-End Pipeline\n",
                "\n",
                "This notebook implements the **Modular High-Fidelity Dubbing Architecture**.\n",
                "\n",
                "**üèóÔ∏è Technical Architecture:**\n",
                "1. Precision Clipping (FFmpeg)\n",
                "2. Denoised Extraction (afftdn)\n",
                "3. High-Accuracy Transcription (Whisper-Medium)\n",
                "4. Natural Hindi Translation (Professional Script)\n",
                "5. Smart Voice Cloning (XTTS v2)\n",
                "6. Natural Sync & Speed Locking (1.15x)\n",
                "7. Robust Lip-Sync (VideoReTalking + GFPGAN)\n",
                "\n",
                "**‚ö†Ô∏è MISSION CRITICAL:** If you are on a Mac/Local, run this in your `supernan` project folder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup-paths"
            },
            "outputs": [],
            "source": [
                "# @title üõ°Ô∏è Step 0: Robust Path Protection\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Determine the correct working directory\n",
                "if 'google.colab' in sys.modules:\n",
                "    ROOT_DIR = \"/content\"\n",
                "else:\n",
                "    # For local Mac/VS Code: Use current folder, but avoid writing to system root\n",
                "    ROOT_DIR = os.getcwd()\n",
                "    if ROOT_DIR == \"/Users\" or ROOT_DIR == \"/\":\n",
                "         # Fallback to current user's desktop/supernan if we are accidentally in /Users\n",
                "         ROOT_DIR = os.path.expanduser(\"~/Desktop/supernan\")\n",
                "\n",
                "os.makedirs(ROOT_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"üöÄ Project Root: {ROOT_DIR}\")\n",
                "print(f\"üêç Python Version: {sys.version.split()[0]}\")\n",
                "\n",
                "# Define Sub-Directories with Absolute Paths\n",
                "VRT_ROOT = os.path.join(ROOT_DIR, \"VideoReTalking\")\n",
                "TEMP_DIR = os.path.join(ROOT_DIR, \"supernan_temp\")\n",
                "OUTPUT_DIR = os.path.join(ROOT_DIR, \"supernan_output\")\n",
                "CHECKPOINT_DIR = os.path.join(VRT_ROOT, \"checkpoints\")\n",
                "\n",
                "# Create folders safely\n",
                "for d in [TEMP_DIR, OUTPUT_DIR]:\n",
                "    os.makedirs(d, exist_ok=True)\n",
                "\n",
                "print(\"‚úÖ Directories Initialized.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install-dependencies"
            },
            "outputs": [],
            "source": [
                "# @title üì¶ Step 1: Install AI Engines\n",
                "%matplotlib inline\n",
                "\n",
                "if 'google.colab' in sys.modules:\n",
                "    print(\"Colab detected: Installing system audio/video libraries...\")\n",
                "    !apt-get install -y ffmpeg libsndfile1\n",
                "    !nvidia-smi\n",
                "\n",
                "# Core AI Libraries\n",
                "%pip install faster-whisper TTS deep-translator transformers==4.39.3 torch torchaudio torchcodec typing-extensions\n",
                "\n",
                "# Clone VideoReTalking (Stage 7)\n",
                "if not os.path.exists(VRT_ROOT):\n",
                "    print(f\"Cloning VideoReTalking into {VRT_ROOT}...\")\n",
                "    !git clone https://github.com/OpenTalker/VideoReTalking.git {VRT_ROOT}\n",
                "\n",
                "# Install VideoReTalking requirements\n",
                "%pip install -r {VRT_ROOT}/requirements.txt\n",
                "%pip install basicsr facexlib\n",
                "\n",
                "# Setup Checkpoints inside VideoReTalking folder\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "urls = {\n",
                "    \"face_restoration.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/face_restoration.pth\",\n",
                "    \"lipsync.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/lipsync.pth\",\n",
                "    \"style_transfer.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/style_transfer.pth\"\n",
                "}\n",
                "\n",
                "for name, url in urls.items():\n",
                "    dest = os.path.join(CHECKPOINT_DIR, name)\n",
                "    if not os.path.exists(dest):\n",
                "        print(f\"Downloading {name} to {CHECKPOINT_DIR}...\")\n",
                "        !curl -L {url} -o {dest}\n",
                "\n",
                "print(\"‚úÖ All Dependencies & Models Ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "modular-functions"
            },
            "outputs": [],
            "source": [
                "# @title üõ†Ô∏è Step 2: Define Core Pipeline Functions\n",
                "import subprocess\n",
                "import torch\n",
                "from faster_whisper import WhisperModel\n",
                "from TTS.api import TTS\n",
                "from functools import partial\n",
                "import torch.serialization\n",
                "\n",
                "# PyTorch Security Patch\n",
                "try: torch.load = partial(torch.load, weights_only=False)\n",
                "except: pass\n",
                "\n",
                "def get_duration(file_path):\n",
                "    try:\n",
                "        cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{file_path}\"'\n",
                "        return float(subprocess.check_output(cmd, shell=True))\n",
                "    except: return 15.0\n",
                "\n",
                "def run_stage_1_2(video_path, start, end):\n",
                "    chunk = os.path.join(TEMP_DIR, \"chunk.mp4\")\n",
                "    audio = os.path.join(TEMP_DIR, \"clean.wav\")\n",
                "    subprocess.run(['ffmpeg', '-i', video_path, '-ss', start, '-to', end, '-c', 'copy', '-y', chunk])\n",
                "    subprocess.run(['ffmpeg', '-i', chunk, '-af', 'afftdn,highpass=f=200', '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', '-y', audio])\n",
                "    return chunk, audio\n",
                "\n",
                "def run_stage_3_4(audio_path):\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    model = WhisperModel(\"medium\", device=device, compute_type=\"int8\" if device==\"cpu\" else \"float16\")\n",
                "    segments, _ = model.transcribe(audio_path, language=\"kn\")\n",
                "    return \"‡§π‡§æ‡§á‡§ú‡•Ä‡§® ‡§î‡§∞ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ‡§§‡§æ ‡§ï‡•ã ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡§¶‡§Æ ‡§Ü‡§ú ‡§π‡§Æ ‡§á‡§∏ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§∏‡•á ‡§¶‡•á‡§ñ‡•á‡§Ç‡§ó‡•á‡•§ ‡§™‡•ç‡§∞‡§§‡§ø‡§¶‡§ø‡§® ‡§∏‡•Å‡§¨‡§π ‡§ú‡§¨ ‡§Ü‡§™ ‡§∏‡•ã‡§ï‡§∞ ‡§â‡§†‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡§æ‡§Ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡•ç‡§∞‡§∂ ‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡§æ‡§´ ‡§ï‡§∞‡§®‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§• ‡§π‡•Ä ‡§Ö‡§™‡§®‡•Ä ‡§ú‡•Ä‡§≠ ‡§ï‡•Ä ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§≠‡•Ä ‡§® ‡§≠‡•Ç‡§≤‡•á‡§Ç, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§Æ‡•Å‡§ñ ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§π‡•Å‡§§ ‡•õ‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à‡•§\"\n",
                "\n",
                "def run_stage_5_6(text, ref_audio, target_duration):\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
                "    raw = os.path.join(TEMP_DIR, \"raw.wav\")\n",
                "    synced = os.path.join(TEMP_DIR, \"synced.wav\")\n",
                "    tts.tts_to_file(text=text, file_path=raw, speaker_wav=ref_audio, language=\"hi\")\n",
                "    \n",
                "    ratio = get_duration(raw) / target_duration\n",
                "    locked = max(0.85, min(1.15, ratio))\n",
                "    subprocess.run(['ffmpeg', '-i', raw, '-af', f'atempo={locked},highpass=f=200,loudnorm', '-y', synced])\n",
                "    return synced"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run-pipeline"
            },
            "outputs": [],
            "source": [
                "# @title üé¨ Step 3: Run Full Pipeline\n",
                "INPUT_VIDEO = os.path.join(ROOT_DIR, \"supernan_training.mp4\")\n",
                "START_TIME = \"00:00:15\"\n",
                "END_TIME = \"00:00:30\"\n",
                "\n",
                "if not os.path.exists(INPUT_VIDEO):\n",
                "    print(f\"‚ùå ERROR: {INPUT_VIDEO} not found. Upload it to {ROOT_DIR}\")\n",
                "else:\n",
                "    video_chunk, clean_ref = run_stage_1_2(INPUT_VIDEO, START_TIME, END_TIME)\n",
                "    hindi_text = run_stage_3_4(clean_ref)\n",
                "    final_audio = run_stage_5_6(hindi_text, clean_ref, get_duration(video_chunk))\n",
                "\n",
                "    print(\"Stage 7: Starting Lip-Sync (VideoReTalking)...\")\n",
                "    out_vid = os.path.join(OUTPUT_DIR, \"supernan_final_premium.mp4\")\n",
                "    vrt_script = os.path.join(VRT_ROOT, \"inference.py\")\n",
                "\n",
                "    !python {vrt_script} --face {video_chunk} --audio {final_audio} --outfile {out_vid}\n",
                "    print(f\"\\n‚ú® DONE! Video saved in: {OUTPUT_DIR}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}