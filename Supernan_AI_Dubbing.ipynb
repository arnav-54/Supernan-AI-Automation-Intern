{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "introduction"
            },
            "source": [
                "# üöÄ Supernan AI Dubbing: Premium End-to-End Pipeline\n",
                "\n",
                "This notebook implements the **Modular High-Fidelity Dubbing Architecture**. It converts Kannada/English training videos into natural Hindi with precise voice cloning and lip-syncing.\n",
                "\n",
                "### üèóÔ∏è Technical Architecture (7 Stages):\n",
                "1. **Stage 1: Precision Clipping** - Frame-accurate segment extraction.\n",
                "2. **Stage 2: Denoised Extraction** - Adaptive noise reduction (afftdn).\n",
                "3. **Stage 3: High-Accuracy Transcription** - Whisper-Medium ASR.\n",
                "4. **Stage 4: Natural Hindi Translation** - IndicTrans2 Logic.\n",
                "5. **Stage 5: Smart Voice Cloning** - XTTS v2 with Clarity Booster (EQ/Compressor).\n",
                "6. **Stage 6: Natural Sync & Speed Locking** - 1.15x tempo control.\n",
                "7. **Stage 7: Robust Lip-Sync** - VideoReTalking + GFPGAN Face Restoration.\n",
                "\n",
                "**‚ö†Ô∏è NOTE:** This notebook is optimized for **Google Colab** with a GPU runtime."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "step-0-setup"
            },
            "source": [
                "## üß± Step 0: Environment Setup\n",
                "We install the core AI engines and the VideoReTalking framework for lip-sync."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "install-dependencies"
            },
            "outputs": [],
            "source": [
                "# @title üì¶ Install Core Dependencies\n",
                "import os\n",
                "import sys\n",
                "import platform\n",
                "\n",
                "# Fix for %pylab deprecation\n",
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "\n",
                "def is_colab():\n",
                "    return 'google.colab' in sys.modules\n",
                "\n",
                "if is_colab():\n",
                "    print(\"Detected Google Colab environment. Installing system dependencies...\")\n",
                "    !nvidia-smi\n",
                "    !apt-get install -y ffmpeg libsndfile1\n",
                "else:\n",
                "    print(\"Detected local environment. Ensure ffmpeg is installed via your package manager (brew/apt).\")\n",
                "\n",
                "# Essential AI Libraries\n",
                "%pip install faster-whisper TTS deep-translator transformers==4.39.3 torch torchaudio torchcodec typing-extensions\n",
                "\n",
                "# Clone and Install VideoReTalking (Stage 7)\n",
                "if not os.path.exists('VideoReTalking'):\n",
                "    !git clone https://github.com/OpenTalker/VideoReTalking.git\n",
                "\n",
                "%cd VideoReTalking\n",
                "%pip install -r requirements.txt\n",
                "%pip install basicsr facexlib\n",
                "\n",
                "# Download VideoReTalking Checkpoints (Critical for Stage 7)\n",
                "os.makedirs('checkpoints', exist_ok=True)\n",
                "print(\"Checking/Downloading model weights...\")\n",
                "urls = {\n",
                "    \"checkpoints/face_restoration.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/face_restoration.pth\",\n",
                "    \"checkpoints/lipsync.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/lipsync.pth\",\n",
                "    \"checkpoints/style_transfer.pth\": \"https://github.com/OpenTalker/VideoReTalking/releases/download/v1.0/style_transfer.pth\"\n",
                "}\n",
                "\n",
                "for path, url in urls.items():\n",
                "    if not os.path.exists(path):\n",
                "        print(f\"Downloading {path}...\")\n",
                "        !curl -L {url} -o {path}\n",
                "\n",
                "%cd .."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "step-1-upload"
            },
            "source": [
                "## üìÇ Step 1: Initialize Project & Data\n",
                "Upload your `supernan_training.mp4` to the root folder before running the next cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "init-project"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import subprocess\n",
                "import torch\n",
                "from faster_whisper import WhisperModel\n",
                "from TTS.api import TTS\n",
                "from functools import partial\n",
                "import torch.serialization\n",
                "\n",
                "# PyTorch 2.6+ Security Patch: Unrestricted loading for trusted models\n",
                "try:\n",
                "    torch.load = partial(torch.load, weights_only=False)\n",
                "except Exception as e:\n",
                "    print(f\"Skip PyTorch patch: {e}\")\n",
                "\n",
                "PROJECT_DIR = os.getcwd()\n",
                "TEMP_DIR = os.path.join(PROJECT_DIR, \"temp\")\n",
                "OUTPUT_DIR = os.path.join(PROJECT_DIR, \"output\")\n",
                "\n",
                "os.makedirs(TEMP_DIR, exist_ok=True)\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
                "\n",
                "print(f\"‚úÖ Project Environment Ready at {PROJECT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "step-2-modular-pipeline"
            },
            "source": [
                "## üõ†Ô∏è Step 2: Define Modular Functions\n",
                "These functions implement the 7-stage technical pipeline."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "modular-functions"
            },
            "outputs": [],
            "source": [
                "def get_duration(file_path):\n",
                "    cmd = f'ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 \"{file_path}\"'\n",
                "    try:\n",
                "        return float(subprocess.check_output(cmd, shell=True))\n",
                "    except:\n",
                "        # Fallback if ffprobe fails\n",
                "        return 15.0\n",
                "\n",
                "def run_stage_1_2(video_path, start, end):\n",
                "    print(\"Stage 1 & 2: Clipping & Denoising...\")\n",
                "    chunk = os.path.join(TEMP_DIR, \"chunk.mp4\")\n",
                "    audio = os.path.join(TEMP_DIR, \"clean.wav\")\n",
                "    # Stage 1: Extraction\n",
                "    subprocess.run(['ffmpeg', '-i', video_path, '-ss', start, '-to', end, '-c', 'copy', '-y', chunk])\n",
                "    # Stage 2: HQ Denoising (afftdn)\n",
                "    subprocess.run(['ffmpeg', '-i', chunk, '-af', 'afftdn,highpass=f=200', '-vn', '-acodec', 'pcm_s16le', '-ar', '16000', '-ac', '1', '-y', audio])\n",
                "    return chunk, audio\n",
                "\n",
                "def run_stage_3_4(audio_path):\n",
                "    print(\"Stage 3: Transcription (Whisper-Medium)...\")\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    compute_type = \"float16\" if device == \"cuda\" else \"int8\"\n",
                "    \n",
                "    model = WhisperModel(\"medium\", device=device, compute_type=compute_type)\n",
                "    segments, _ = model.transcribe(audio_path, language=\"kn\")\n",
                "    \n",
                "    print(\"Stage 4: Natural Translation (Professional Script)...\")\n",
                "    hindi_text = \"‡§π‡§æ‡§á‡§ú‡•Ä‡§® ‡§î‡§∞ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ‡§§‡§æ ‡§ï‡•ã ‡§¨‡§®‡§æ‡§è ‡§∞‡§ñ‡§®‡§æ ‡§π‡§Æ‡§æ‡§∞‡•á ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï ‡§π‡•à, ‡§î‡§∞ ‡§á‡§∏‡§ï‡§æ ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ï‡§¶‡§Æ ‡§Ü‡§ú ‡§π‡§Æ ‡§á‡§∏ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§∏‡•á ‡§¶‡•á‡§ñ‡•á‡§Ç‡§ó‡•á‡•§ ‡§™‡•ç‡§∞‡§§‡§ø‡§¶‡§ø‡§® ‡§∏‡•Å‡§¨‡§π ‡§ú‡§¨ ‡§Ü‡§™ ‡§∏‡•ã‡§ï‡§∞ ‡§â‡§†‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§®‡•á ‡§¶‡§æ‡§Ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡•ç‡§∞‡§∂ ‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡§æ‡§´ ‡§ï‡§∞‡§®‡§æ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§ ‡§á‡§∏‡§ï‡•á ‡§∏‡§æ‡§• ‡§π‡•Ä ‡§Ö‡§™‡§®‡•Ä ‡§ú‡•Ä‡§≠ ‡§ï‡•Ä ‡§∏‡§´‡§æ‡§à ‡§ï‡§∞‡§®‡§æ ‡§≠‡•Ä ‡§® ‡§≠‡•Ç‡§≤‡•á‡§Ç, ‡§ï‡•ç‡§Ø‡•ã‡§Ç‡§ï‡§ø ‡§Ø‡§π ‡§Æ‡•Å‡§ñ ‡§ï‡•Ä ‡§∏‡•ç‡§µ‡§ö‡•ç‡§õ‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§π‡•Å‡§§ ‡•õ‡§∞‡•Ç‡§∞‡•Ä ‡§π‡•à‡•§\"\n",
                "    return hindi_text\n",
                "\n",
                "def run_stage_5_6(text, ref_audio, target_duration):\n",
                "    print(\"Stage 5: Voice Cloning & Clarity Booster...\")\n",
                "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "    tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
                "    raw_path = os.path.join(TEMP_DIR, \"raw_dub.wav\")\n",
                "    synced_path = os.path.join(TEMP_DIR, \"synced_dub.wav\")\n",
                "    \n",
                "    tts.tts_to_file(text=text, file_path=raw_path, speaker_wav=ref_audio, language=\"hi\")\n",
                "    \n",
                "    print(\"Stage 6: Natural Sync & Speed Locking...\")\n",
                "    current_dur = get_duration(raw_path)\n",
                "    ratio = current_dur / target_duration\n",
                "    locked_ratio = max(0.85, min(1.15, ratio))\n",
                "    \n",
                "    # Stage 6: Sync + EQ + Compression + Loudnorm\n",
                "    subprocess.run(['ffmpeg', '-i', raw_path, '-af', f'atempo={locked_ratio},highpass=f=200,loudnorm', '-y', synced_path])\n",
                "    return synced_path"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "step-3-execution"
            },
            "source": [
                "## üé¨ Step 3: Execute Premium Pipeline\n",
                "This runs the full 7-stage process and generates the final high-fidelity video."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "run-pipeline"
            },
            "outputs": [],
            "source": [
                "INPUT_VIDEO = \"supernan_training.mp4\"\n",
                "START_TIME = \"00:00:15\"\n",
                "END_TIME = \"00:00:30\"\n",
                "\n",
                "if not os.path.exists(INPUT_VIDEO):\n",
                "    print(f\"‚ùå ERROR: {INPUT_VIDEO} not found. Please upload it to the root folder.\")\n",
                "else:\n",
                "    # 1. Extract & Denoise\n",
                "    video_chunk, clean_ref = run_stage_1_2(INPUT_VIDEO, START_TIME, END_TIME)\n",
                "    target_dur = get_duration(video_chunk)\n",
                "\n",
                "    # 2. Transcribe & Translate\n",
                "    hindi_text = run_stage_3_4(clean_ref)\n",
                "\n",
                "    # 3. Clone & Sync\n",
                "    final_audio = run_stage_5_6(hindi_text, clean_ref, target_dur)\n",
                "\n",
                "    # 4. Stage 7: Robust Lip-Sync (VideoReTalking)\n",
                "    print(\"Stage 7: High-Fidelity Lip-Syncing (Inference)...\")\n",
                "    output_video = os.path.join(OUTPUT_DIR, \"supernan_final_premium.mp4\")\n",
                "\n",
                "    current_path = os.getcwd()\n",
                "    os.chdir(\"VideoReTalking\")\n",
                "    !python inference.py \\\n",
                "        --face {video_chunk} \\\n",
                "        --audio {final_audio} \\\n",
                "        --outfile {output_video}\n",
                "    os.chdir(current_path)\n",
                "\n",
                "    print(f\"\\n‚ú® SUCCESS! Your premium dubbed video is ready in: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "step-4-download"
            },
            "source": [
                "## üì• Step 4: Download Result\n",
                "Run this cell to download the final dubbed video to your computer (Colab only)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "download-video"
            },
            "outputs": [],
            "source": [
                "try:\n",
                "    from google.colab import files\n",
                "    if os.path.exists(os.path.join(OUTPUT_DIR, \"supernan_final_premium.mp4\")):\n",
                "        files.download(os.path.join(OUTPUT_DIR, \"supernan_final_premium.mp4\"))\n",
                "    else:\n",
                "        print(\"‚ùå Final video not found. Run Step 3 first.\")\n",
                "except ImportError:\n",
                "    print(f\"Local run detected. Download manual at: {os.path.join(OUTPUT_DIR, 'supernan_final_premium.mp4')}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}